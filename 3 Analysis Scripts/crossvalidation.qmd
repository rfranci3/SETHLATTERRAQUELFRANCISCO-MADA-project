---
title: "Cross Validation"
format: html
editor: visual
---

# Ciconia ciconia analysis script

#### this script loads the processed, cleaned data, does a simple analysis and saves the results to the results folder

```{r, warning=FALSE, message=FALSE}
#load needed packages. make sure they are installed.
library(ggplot2) #for plotting
library(ggeffects) #to explore plots  
library(broom) #for cleaning up output from lm()
library(broom.mixed) #for cleaning up output from lmer()
library(here) #for data loading/saving
library(multilevelmod) #mixed effect models
library(tidymodels)
library(lme4)
library(sjPlot) #to help plot models
library(performance) #evaluate model fit and performance
library(see)
library(cAIC4)
library(rpart)
library(rpart.plot)
library(glmertree)

#path to data
data_location <- here::here("2 Clean Data","stork_AMR_clean.rds")

#load data. 
data <- readRDS(data_location)
```

```{r}
# Set seed
set.seed(2023)

# Put 3/4 of the data into the training set 
data_split <- initial_split(data, prop = 3/4)

# Create data frames for the two sets
train_data <- training(data_split)
test_data  <- testing(data_split)
```

```{r}
# 5-fold cross-validation, 5 times repeated, using MDR as strata 
folds <- vfold_cv(train_data, v = 5, repeats = 5, strata = MDR)

#create model and set engine
tree_model <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("regression")

#create tree workflow for global model
tree_workflow_global <- workflow() %>%
  add_model(tree_model) %>%
  add_formula(Burden ~ s.lui + s.age + samp + s.nsuccess)

#tree grid
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5)

#tree_resamples
tree_resamp <- 
  tree_workflow_global %>% 
  tune_grid(
    resamples = folds,
    grid = tree_grid
    )

tree_resamp %>%
  collect_metrics()

tree_resamp %>%
  autoplot()

#select best tree model
best_tree <- tree_resamp %>%
  select_best(metric = 'rmse')

#final model
final_tree <- tree_workflow_global %>%
  finalize_workflow(best_tree)

#fit final model to data
tree_fit_final <- final_tree %>%
  fit(train_data)

#plot final fit
rpart.plot::rpart.plot(extract_fit_parsnip(tree_fit_final)$fit)

#tree residual plot
tree_pred <- tree_fit_final %>%
  fit(train_data) %>%
  predict(train_data)

tree_resid <- train_data$Burden - tree_pred$.pred
tree_df <- tibble(tree_resid, tree_pred)

ggplot(aes(.pred, tree_resid), data = tree_df)+
  geom_point()+
  labs(x = "Predictions", y = "Residuals")+
  geom_hline(yintercept = 0)+
  theme_bw()
```

```{r}
#create model and set engine
tree_model2 <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

#create tree workflow for global model
tree_workflow_global2 <- workflow() %>%
  add_model(tree_model2) %>%
  add_formula(as.factor(MDR) ~ s.lui + s.age + samp + s.nsuccess)


#tree_resamples
tree_resamp2 <- 
  tree_workflow_global2 %>% 
  tune_grid(
    resamples = folds,
    grid = tree_grid
    )

tree_resamp2 %>%
  collect_metrics()

tree_resamp2 %>%
  autoplot()

#select best tree model
best_tree2 <- tree_resamp2 %>%
  select_best()

#final model
final_tree2 <- tree_workflow_global2 %>%
  finalize_workflow(best_tree2)

#fit final model to data
tree_fit_final2 <- final_tree2 %>%
  fit(train_data)

#plot final fit
rpart.plot::rpart.plot(extract_fit_parsnip(tree_fit_final2)$fit)

#tree residual plot
tree_pred2 <- tree_fit_final2 %>%
  fit(train_data) %>%
  predict(train_data)

tree_resid2 <- train_data$MDR - tree_pred$.pred
tree_df2 <- tibble(tree_resid2, tree_pred2)
```

